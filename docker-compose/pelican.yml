services:
  panel:
    image: ghcr.io/pelican-dev/panel:v1.0.0-beta30@sha256:aec08833e40b54e773cae68945d81f42561d176244032e33c152a92ebd0e0deb
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: ${PANEL_CPULIMIT:-2}
          #memory: 50M
    depends_on:
      database:
        condition: service_started
        restart: true
      cache:
        condition: service_started
        restart: true
    restart: unless-stopped
    healthcheck:
       test: wget --no-verbose --tries=1 --spider http://127.0.0.1/up || exit 1
       interval: 30s
       timeout: 25s
       retries: 3
       start_period: 30s
    networks:
      Management:
        aliases:
          - panel
    volumes:
      - panel-data:/pelican-data
      - panel-logs:/var/www/html/storage/logs
    environment:
      TZ: ${TZ:-UTC}
      APP_URL: https://${PANEL_SUBDOMAIN:-panel}.${DOMAIN}
      APP_NAME: ${APP_NAME:-Pelican}
      APP_KEY: ${APP_KEY}  ### 32 character random password
      APP_DEBUG: ${DEBUG:-false}
      APP_ENV: production
      APP_LOCALE: ${LOCALE:-en}
      BEHIND_PROXY: true
      TRUSTED_PROXIES: '*'
      DB_CONNECTION: mariadb
      DB_HOST: database
      DB_PORT: 3306
      DB_DATABASE: pelican
      MYSQL_DATABASE: pelican
      DB_USERNAME: pelican
      DB_PASSWORD: ${MYSQL_PASS}
      CACHE_STORE: redis
      SESSION_DRIVER: redis
      QUEUE_CONNECTION: redis
      REDIS_HOST: cache
      MAIL_DRIVER: ${MAIL_DRIVER:-smtp}
      MAIL_MAILER: ${MAIL_DRIVER:-smtp}
      MAIL_HOST: ${MAIL_SERVER:-smtp.gmail.com}
      MAIL_PORT: ${MAIL_PORT:-465}
      MAIL_FROM: ${MAIL_FROM}
      MAIL_FROM_ADDRESS: ${MAIL_FROM}
      MAIL_FROM_NAME: ${MAIL_FROM_NAME:-Pelican}
      MAIL_USERNAME: ${MAIL_USERNAME}
      MAIL_PASSWORD: ${MAIL_PASSWORD}
      MAIL_SCHEME: ${MAIL_SCHEME:-smtps}
      SKIP_CADDY: ${SKIP_CADDY:-false} # enable when not using caddy.
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    labels:
      - dfpelican.enable=true
      - dfpelican.0.hostname=${PANEL_SUBDOMAIN:-panel}.${DOMAIN}
      - dfpelican.0.service=http://panel:80
      - dfpelican.0.access.policy=bypass
      - dfpelican.0.zonename=${DOMAIN}
      - AutohealPelican=true

  database:
    image: mariadb:10.11
    restart: unless-stopped
    command: --default-authentication-plugin=mysql_native_password
    deploy:
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 5
        window: 120s
    volumes:
      - database:/var/lib/mysql
    networks:
      Management:
        aliases:
          - database
      wings:
        aliases:
          - database
    healthcheck:
      test: ["CMD", "healthcheck.sh", "--su-mysql", "--connect", "--innodb_initialized"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASS}
      MYSQL_PASSWORD: ${MYSQL_PASS}
      MYSQL_DATABASE: "pelican"
      MYSQL_USER: "pelican"
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    labels:
      - AutohealPelican=true

  cache:
    image: redis:alpine
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 5
        window: 120s
    networks:
      Management:
        aliases:
          - cache
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    labels:
      - AutohealPelican=true

  dockflare:
    image: alplat/dockflare:v2.0.4
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: ${DOCKFLARE_CPULIMIT:-2}
    networks:
      Management:
        aliases:
          - dockflare
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:5000 -O /dev/null || exit 1
      interval: 30s
      retries: 3
      start_period: 30s
      timeout: 20s 
    environment:
      - TUNNEL_NAME=pelican
      - LABEL_PREFIX=dfpelican
      - CLOUDFLARED_NETWORK_NAME=pelican-mgmt
      - CLOUDFLARED_IMAGE=cloudflare/cloudflared:latest
      - TZ=${TZ:-Australia/Melbourne}
      - CF_API_TOKEN=${CF_APITOKEN}
      - CF_ACCOUNT_ID=${CF_ACCOUNTID}
      - AGENT_STATUS_UPDATE_INTERVAL_SECONDS=5
      - SYNC_ALL_CLOUDFLARE_POLICIES=true
      - TZ=${TZ:-UTC}
      - GRACE_PERIOD_SECONDS=28800
      - CLEANUP_INTERVAL_SECONDS=900
      - SCAN_ALL_NETWORKS=false
      - MAX_CONCURRENT_DNS_OPS=${DOCKFLARE_DNSOPS:-2}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - dockflare:/app/data
    labels:
      - AutohealPelican=true

  crowdsec-engine:
    image: crowdsecurity/crowdsec:v1.7.4@sha256:4312a5109057f2a6b1237431abe638cd1026ecb3a9c2707c6ccc1ed09e4cb994
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: ${CROWDSEC_CPULIMIT:-2}
    restart: unless-stopped
    ports:
      - ${CROWDSEC_PORT:-8080}:8080
    depends_on:
      init-crowdsec:
        condition: service_completed_successfully
    environment:
      - COLLECTIONS=lourys/pterodactyl
      - BOUNCER_KEY_FIREWALL=${CROWDSEC_KEY:-my_super_secret_key_123}
      - DISABLE_ONLINE_API=false
    volumes:
      - crowdsec-data:/var/lib/crowdsec/data
      - crowdsec-config:/etc/crowdsec
      - bouncer-config:/etc/bouncer-shared
      - /var/log/pelican:/var/log/pelican:ro
    healthcheck:  
      test: ["CMD", "cscli", "version"]
    labels:
      - PelicanAutoheal=true
    networks:
      Management:
        aliases:
          - crowdsec

  crowdsecbouncer-cloudflare:
    image: ghcr.io/crowdsecurity/cloudflare-bouncer:v0.3.0@sha256:39719a070c154866ebc81335e70fdfa1c61eac45025fee7d9bbf8da689fbb2c6
    deploy:
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 6
        window: 60s
      resources:
        limits:
          cpus: ${CROWDSEC_CPULIMIT:-2}
    restart: unless-stopped
    depends_on:
      crowdsec-engine:
        condition: service_started
    environment:
      API_URL: http://crowdsec:8080
      API_KEY: ${CROWDSEC_KEY:-my_super_secret_key_123}
      CF_APITOKEN: ${CF_APITOKEN}
      CF_ACCOUNTID: ${CF_ACCOUNTID}
      CF_ZONE_ID: ${CF_ZONE_ID}
    volumes:
      - bouncer-config:/etc/crowdsec/bouncers/:rw
      - /etc/localtime:/etc/localtime:ro
    networks:
      - Management

  autoheal:
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 5
        window: 120s
    environment:
      AUTOHEAL_CONTAINER_LABEL: AutohealPelican
      AUTOHEAL_INTERVAL: 60
      AUTOHEAL_START_PERIOD: 240
      AUTOHEAL_DEFAULT_STOP_TIMEOUT: 60
      WEBHOOK_URL: ${AUTOHEAL_WEBHOOK:-}
    image: willfarrell/autoheal@sha256:732faa8b31f94002728d663f2090d37a109fff5b5fe8654a300fddac5f77c1c4
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock

  init-crowdsec:
    image: alpine:latest
    volumes:
      - crowdsec-config:/etc/crowdsec
      - bouncer-config:/etc/crowdsec/bouncers
    command: >
      sh -c "apk add --no-cache wget ca-certificates &&
             mkdir -p /etc/crowdsec/acquisitions.d /etc/crowdsec/bouncers &&
             wget -qO /etc/crowdsec/acquis.yaml https://raw.githubusercontent.com/trentnbauer/HomelabPublic/main/crowdsec/pterodactyl.yaml &&
             wget -qO /etc/crowdsec/bouncers/crowdsec-cloudflare-bouncer.yaml https://raw.githubusercontent.com/trentnbauer/HomelabPublic/main/crowdsec/crowdsec-cloudflare-bouncer.yaml"
     
volumes:
  panel-data:
  panel-logs:
  database:
  dockflare:
  crowdsec-data:
  crowdsec-config:
  bouncer-config:
  
networks:
  Management:
    name: pelican-mgmt
    ipam:
       config:
       - subnet: 192.168.253.0/24
         gateway: 192.168.253.1
  wings:
    name: pelican_nw
    ipam:
       config:
       - subnet: 192.168.254.0/24
         gateway: 192.168.254.1
